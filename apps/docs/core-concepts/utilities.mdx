---
title: Adding Cloudflare and self hosted models support
description: Documentation on adding new models to be used when creating AI Agents.
---

### Cloudflare AI Models

New models from Cloudflare AI have been added to our token cost calculations. These models offer a range of capabilities, from chat-based interactions to instruction following, and vary in size from 7 billion to 70 billion parameters. The token costs for these models are designed to reflect their computational requirements and provide users with cost-effective options for integrating advanced AI capabilities into their applications.

The following Cloudflare AI models have been added:

- `@cf/meta/llama-2-7b-chat-int8`
- `@cf/meta/llama-2-13b-chat-int8`
- `@cf/meta/llama-2-70b-chat-int8`
- `@cf/mistral/mistral-7b-instruct-v0.1`
- `@cf/tiiuae/falcon-7b-instruct`
- `@cf/anthropic/claude-instant-1.2`
- `@cf/anthropic/claude-2.1`

Additionally, a `custom-http-model` option has been included to accommodate custom model integrations, providing flexibility for users with specific needs.

### Modified Utilities

The `tokenCounter` utility has been updated to include the new models and their respective token costs. This utility is essential for calculating the number of tokens consumed by a model operation, which in turn helps in estimating the cost associated with using different AI models.

The token costs for the newly added models are as follows:

```typescript
const MODEL_COSTS = {
  "@cf/meta/llama-2-7b-chat-int8": { input: 0.2, output: 0.4 },
  "@cf/meta/llama-2-13b-chat-int8": { input: 0.4, output: 0.8 },
  "@cf/meta/llama-2-70b-chat-int8": { input: 1.0, output: 2.0 },
  "@cf/mistral/mistral-7b-instruct-v0.1": { input: 0.2, output: 0.4 },
  "@cf/tiiuae/falcon-7b-instruct": { input: 0.2, output: 0.4 },
  "@cf/anthropic/claude-instant-1.2": { input: 0.8, output: 2.4 },
  "@cf/anthropic/claude-2.1": { input: 8.0, output: 24.0 },
  "custom-http-model": { input: 0.5, output: 1.5 },
};
```

### Example of Updated Token Cost Calculation

To calculate the token cost for using the `@cf/meta/llama-2-13b-chat-int8` model for an operation that includes 100 input tokens and generates 250 output tokens, you can use the updated `tokenCounter` utility as follows:

```typescript
import { calculateTokenCost } from 'path-to-tokenCounter';

const modelId = "@cf/meta/llama-2-13b-chat-int8";
const inputTokens = 100;
const outputTokens = 250;

const cost = calculateTokenCost(modelId, inputTokens, outputTokens);
console.log(`Token cost for the operation: ${cost}`);
```

This update ensures that users have access to the latest AI models and can accurately calculate costs, facilitating more informed decision-making regarding the integration of AI capabilities into their applications.
